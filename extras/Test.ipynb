{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-04 15:22:03.782124: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-04 15:22:03.799097: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-04 15:22:03.866898: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-04 15:22:03.972852: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-04 15:22:04.004382: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-04 15:22:04.087827: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-04 15:22:09.348579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: This is Wonderful. I love this movie\n",
      "Processed input: [[ 14   6 634  40 110  14  18]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Sentiment: Positive\n",
      "\n",
      "Input text: This is terrible. I hate this movie\n",
      "Processed input: [[  14    6  747   40 1255   14   18]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Sentiment: Negative\n",
      "\n",
      "Input text: Not bad, but could be better\n",
      "Processed input: [[ 22 124  12  98  20 111]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Sentiment: Neutral\n",
      "\n",
      "Input text: Absolutely fantastic! Highly recommended\n",
      "Processed input: [[ 748  828  771 3976]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Sentiment: Positive\n",
      "\n",
      "Input text: Worst experience ever. Do not watch\n",
      "Processed input: [[342 252 167 114  22 214]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Sentiment: Negative\n",
      "\n",
      "Input text: This movie was an absolute delight from start to finish. The cinematography was breathtaking, capturing the beauty of each scene with such precision and artistry. The storyline was compelling and kept me engaged throughout the entire film. The character development was exceptional, allowing the audience to connect with each character on a deep and emotional level. The performances by the actors were nothing short of brilliant, each bringing their character to life with such authenticity and passion. The music score was also a highlight, perfectly complementing the tone and mood of the movie. The director did an outstanding job of bringing all the elements together to create a cohesive and memorable experience. The pacing of the movie was perfect, with each scene flowing seamlessly into the next. The dialogue was well-written and delivered with conviction, adding to the overall impact of the film. The special effects were impressive and added to the visual spectacle without overwhelming the story. The themes explored in the movie were thought-provoking and relevant, leaving a lasting impression on the audience. The attention to detail in every aspect of the film was evident and greatly appreciated. Overall, this movie is a masterpiece that deserves all the accolades it has received. It is a must-watch for anyone who appreciates great filmmaking and storytelling. I would highly recommend it to anyone looking for a movie that is both entertaining and meaningful. It is a film that will stay with you long after the credits have rolled.\n",
      "Processed input: [[  14   18   67   17 1871  995   28  503    5 1221    1  962   67 1927\n",
      "  2473    1  578    4  340  360   13  155 2952    3 2532    1 1240   67\n",
      "   286    3 1881  176 2714  625    1  671   16    1  131 1121   67 2062\n",
      "  2710    1  184    5 1972   13  340  131   19    2  572    3  219  402\n",
      "     1  135   24    1  229  161  152  321    4  570  340 1805   59  131\n",
      "     5   96   13  155 1959    3  878    1  308  847   67  121    2 3326\n",
      "   654    1  365    3  862    4    1   18    1   84  383   17 1806  544\n",
      "     4 1805   30    1  440  251    5  803    2 3690    3  686  252    1\n",
      "  1115    4    1   18   67  375   13  340  360   43    1  399    1  253\n",
      "    67    3 1486   13 2166 3054    5    1  606  896    4    1   16    1\n",
      "   313  289  161  471    3 2848    5    1  295  725  136 2738    1   39\n",
      "     1  666 3793    7    1   18  161 1488    3 1889 1106    2 2826 1615\n",
      "    19    1  184    1  565    5 1023    7  137 2083    4    1   16   67\n",
      "  3508    3 4944 3794  606   14   18    6    2  780    9  597   30    1\n",
      "    10   33   10    6    2   15  341   50   93  359    3  401   40   95\n",
      "   771 1206   10    5  341  414   15    2   18    9    6  138  166    3\n",
      "  1769   10    6    2   16    9   51 1083   13   21  147  180    1 1084\n",
      "    35 4877    0    0    0    0    0    0    0    0]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model(\"sentiment_analysis_model.h5\")\n",
    "\n",
    "# Load the tokenizer\n",
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Function to preprocess the text input\n",
    "def preprocess_text(text, tokenizer):\n",
    "    # Clean the text\n",
    "    text = clean_text(text)\n",
    "    # Calculate max sequence length based on the number of words in the input text\n",
    "    max_len = len(text.split())\n",
    "    # Convert the text to sequences\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    # Pad the sequences\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "    return padded_sequences\n",
    "\n",
    "# Function to interpret prediction\n",
    "def interpret_prediction(prediction):\n",
    "    if prediction < 0.4:\n",
    "        return 'Negative'\n",
    "    elif 0.4 <= prediction <= 0.7:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "# Example text inputs\n",
    "input_texts = [\n",
    "    \"This is Wonderful. I love this movie\",\n",
    "    \"This is terrible. I hate this movie\",\n",
    "    \"Not bad, but could be better\",\n",
    "    \"Absolutely fantastic! Highly recommended\",\n",
    "    \"Worst experience ever. Do not watch\",\n",
    "    \"This movie was an absolute delight from start to finish. The cinematography was breathtaking, capturing the beauty of each scene with such precision and artistry. The storyline was compelling and kept me engaged throughout the entire film. The character development was exceptional, allowing the audience to connect with each character on a deep and emotional level. The performances by the actors were nothing short of brilliant, each bringing their character to life with such authenticity and passion. The music score was also a highlight, perfectly complementing the tone and mood of the movie. The director did an outstanding job of bringing all the elements together to create a cohesive and memorable experience. The pacing of the movie was perfect, with each scene flowing seamlessly into the next. The dialogue was well-written and delivered with conviction, adding to the overall impact of the film. The special effects were impressive and added to the visual spectacle without overwhelming the story. The themes explored in the movie were thought-provoking and relevant, leaving a lasting impression on the audience. The attention to detail in every aspect of the film was evident and greatly appreciated. Overall, this movie is a masterpiece that deserves all the accolades it has received. It is a must-watch for anyone who appreciates great filmmaking and storytelling. I would highly recommend it to anyone looking for a movie that is both entertaining and meaningful. It is a film that will stay with you long after the credits have rolled.\"\n",
    "]\n",
    "\n",
    "# Predict for each input text\n",
    "for input_text in input_texts:\n",
    "    processed_input = preprocess_text(input_text, tokenizer)\n",
    "    print(f\"Input text: {input_text}\")\n",
    "    print(f\"Processed input: {processed_input}\")\n",
    "    prediction = model.predict(processed_input)\n",
    "    sentiment = interpret_prediction(prediction[0][0])\n",
    "    print(f\"Sentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========= Loaded RNN Model =========]\n",
      "[========= Loaded Tokenizer =========]\n",
      "Input text: Hop on the Royal Enfield.\n",
      "Processed input: [[  19    1 4580    0    0]]\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x75dc6c79bba0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x75dc6c79bba0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Sentiment: Positive\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rnnmodel import *\n",
    "\n",
    "init_models()\n",
    "\n",
    "get_sentiment(\"Hop on the Royal Enfield.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
